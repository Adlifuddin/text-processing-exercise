{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import spacy\r\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "text = \"I am the happiest person. I have a cat.\"\r\n",
    "doc = nlp(text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "## WORD TOKENIZE\r\n",
    "## Tokenize words to get the tokens of the text i.e breaking the sentences into words.\r\n",
    "from collections import Counter\r\n",
    "words = [token.text for token in doc]\r\n",
    "words"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['I', 'am', 'the', 'happiest', 'person', '.', 'I', 'have', 'a', 'cat', '.']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## SENTENCE TOKENIZE\r\n",
    "## Tokenize sentences if the there are more than 1 sentence i.e breaking the sentences to list of sentence.\r\n",
    "list(doc.sents)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[I am the happiest person., I have a cat.]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "## STOP WORDS REMOVAL\r\n",
    "## Remove irrelevant words using nltk stop words like is,the,a etc from the sentences as they donâ€™t carry any information.\r\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\r\n",
    "words"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['happiest', 'person', 'cat']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "## Lemma\r\n",
    "## lemmatize the text so as to get its root form eg: functions,funtionality as function\r\n",
    "for token in doc:\r\n",
    "    print(token, token.lemma_, token.lower_, token.lemma_.lower().strip())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I I i\n",
      "am be am\n",
      "the the the\n",
      "happiest happy happiest\n",
      "person person person\n",
      ". . .\n",
      "I I i\n",
      "have have have\n",
      "a a a\n",
      "cat cat cat\n",
      ". . .\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "## Get word frequency\r\n",
    "## counting the word occurrence using FreqDist library. Word frequency helps us to determine how important the word is in the document \r\n",
    "## by knowing how many times the word is being used.\r\n",
    "\r\n",
    "#remove stopwords and punctuations\r\n",
    "words = [token.text for token in doc if token.is_stop != True and token.is_punct != True]\r\n",
    "word_freq = Counter(words)\r\n",
    "common_words = word_freq.most_common(5)\r\n",
    "for key, value in common_words:\r\n",
    "    print(f\"{key}: {value}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "happiest: 1\n",
      "person: 1\n",
      "cat: 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "## POS tags\r\n",
    "## POS tag helps us to know the tags of each word like whether a word is noun, adjective etc.\r\n",
    "for w in doc:\r\n",
    "    print (w, w.pos_)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I PRON\n",
      "am AUX\n",
      "the DET\n",
      "happiest ADJ\n",
      "person NOUN\n",
      ". PUNCT\n",
      "I PRON\n",
      "have VERB\n",
      "a DET\n",
      "cat NOUN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "fa3fb38b5f65cee2ff0a035c4da5328998564043868f6520890cc31ef10c108b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}