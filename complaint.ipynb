{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data = pd.read_csv('datasets/train_reviews.csv')\r\n",
    "data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Review  Sentiment\n",
       "0  Absolutely wonderful - silky and sexy and comf...          1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...          1\n",
       "2  I had such high hopes for this dress and reall...          0\n",
       "3  I love, love, love this jumpsuit. it's fun, fl...          1\n",
       "4  This shirt is very flattering to all due to th...          1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data = data.dropna(axis = 0, how ='any')\r\n",
    "len(data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "24641"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "data = data.drop(['Sentiment'],axis=1)\r\n",
    "data.rename(columns = {'Review': 'Text'}, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "category = {}\r\n",
    "\r\n",
    "category['feedback'] = ['opinion', 'think', 'idea', 'suggest', 'recommend', 'propose', 'improve', 'add', 'advise', 'propose', 'comment', \r\n",
    "                        'commend', 'tip', 'view', 'mind', 'conclusion', 'feel', 'feedback', 'feel', 'usually']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for k, v in category.items():\r\n",
    "    v = {w.lower() for w in v}\r\n",
    "    category[k] = v"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# category['feedback']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "from collections import Counter\r\n",
    "import string\r\n",
    "import spacy\r\n",
    "import re\r\n",
    "\r\n",
    "punctuation_auto = list(string.punctuation)\r\n",
    "punctuation_custom = [ '...', '…' ]\r\n",
    "punctuation = np.unique(punctuation_auto+punctuation_custom)\r\n",
    "\r\n",
    "def trends_tags(data,str_input):\r\n",
    "    tag_re = '[^ ]*#[^ ]*'\r\n",
    "    tags_list = []\r\n",
    "    temp = []\r\n",
    "    for index, row in data.iterrows():\r\n",
    "        tokens = str(row[str_input]).split() \r\n",
    "        for word in tokens:\r\n",
    "            if (re.match(tag_re, word)):\r\n",
    "                tags_list.append(word)\r\n",
    "\r\n",
    "    common_words = Counter(tags_list).most_common(3)\r\n",
    "    for key, value in common_words:\r\n",
    "        temp.append({'name': key, 'value': value})\r\n",
    "\r\n",
    "    return temp\r\n",
    "\r\n",
    "def light_text_cleaning_english(text):\r\n",
    "    text = text.lower()\r\n",
    "    text = re.sub('\\[.*?\\]', '', text)\r\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\r\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\r\n",
    "    text = re.sub('[‘’“”…]', '', text)\r\n",
    "    text = re.sub('\\n', '', text)\r\n",
    "\r\n",
    "    # remove numbers\r\n",
    "    text = re.sub(r'\\d+', '', text)\r\n",
    "    # remove links\r\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\r\n",
    "    # remove word with tweethandle @name\r\n",
    "    text = re.sub('[^ ]*@[^ ]*', '', text)\r\n",
    "\r\n",
    "    return text\r\n",
    "\r\n",
    "# def text_cleaning_english(text,mynlp):\r\n",
    "\r\n",
    "#     # remove numbers\r\n",
    "#     text = re.sub(r'\\d+', '', text)\r\n",
    "#     # remove links\r\n",
    "#     text = re.sub('http[s]?://\\S+', '', text)\r\n",
    "#     # remove word with tweethandle @name\r\n",
    "#     text = re.sub('[^ ]*@[^ ]*', '', text)\r\n",
    "\r\n",
    "#     doc = mynlp(text)\r\n",
    "    \r\n",
    "#     # Lemmatization\r\n",
    "#     tokens = []\r\n",
    "#     for token in doc:\r\n",
    "#         if token.lemma_ != \"-PRON-\":\r\n",
    "#             temp = token.lemma_.lower().strip()\r\n",
    "#         else:\r\n",
    "#             temp = token.lower_\r\n",
    "#         tokens.append(temp)\r\n",
    "    \r\n",
    "#     # Remove punctuation and stopwords\r\n",
    "#     cleaned_tokens = []\r\n",
    "#     for token in tokens:\r\n",
    "#         if token not in list(STOP_WORDS) and token not in punctuation:\r\n",
    "#             cleaned_tokens.append(token)\r\n",
    "\r\n",
    "#     # traverse in the string     \r\n",
    "#     complete_sentence = ' '.join([str(words) for words in cleaned_tokens])\r\n",
    "\r\n",
    "#     return complete_sentence\r\n",
    "\r\n",
    "def most_used_words(data,str_input):\r\n",
    "\r\n",
    "    words_list = []\r\n",
    "    temp = []\r\n",
    "    for index, row in data.iterrows():\r\n",
    "        # print(type(row['cleaned_'+str_input]))\r\n",
    "        tokens = str(row['Cleaned_'+str_input]).split() \r\n",
    "        for word in tokens:\r\n",
    "            if word not in list(STOP_WORDS):\r\n",
    "                words_list.append(word)\r\n",
    "\r\n",
    "    common_words = Counter(words_list).most_common(50)\r\n",
    "    for key, value in common_words:\r\n",
    "        temp.append({'name': key, 'value': value})\r\n",
    "\r\n",
    "    return temp\r\n",
    "\r\n",
    "def word_finder(data,str_input):\r\n",
    "    words_list = []\r\n",
    "    predicted = []\r\n",
    "    for index, row in data.iterrows():\r\n",
    "        # print(row['Cleaned_'+str_input])\r\n",
    "        check = False\r\n",
    "        tokens = str(row['Cleaned_'+str_input]).split() \r\n",
    "        for word in tokens:\r\n",
    "            if word in list(category['feedback']):\r\n",
    "                check = True\r\n",
    "        \r\n",
    "        if check:\r\n",
    "            words_list.append(str(row['Cleaned_'+str_input]))\r\n",
    "            predicted.append('Feedback')\r\n",
    "        else:\r\n",
    "            predicted.append('Non-Feedback')\r\n",
    "\r\n",
    "    return words_list, predicted"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test = {'Text': [\r\n",
    "    'In my opinion this is a good product #goodquality',\r\n",
    "    'I think it would be great if you could add more features #highquality',\r\n",
    "    'I like it #goodquality #mychoice',\r\n",
    "    'Good product and quality',\r\n",
    "    'This product is recommended for all',\r\n",
    "    'Would buy the product again next time #goodquality #recommended',\r\n",
    "]}\r\n",
    "test_data = pd.DataFrame(test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get text contain the words\r\n",
    "tag_list = trends_tags(test_data,'Text')\r\n",
    "tag_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'name': '#goodquality', 'value': 3},\n",
       " {'name': '#highquality', 'value': 1},\n",
       " {'name': '#mychoice', 'value': 1}]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "text_cleaning = lambda x: light_text_cleaning_english(x)\r\n",
    "data['Cleaned_Text'] = pd.DataFrame(data['Text'].apply(text_cleaning))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# get text contain the words\r\n",
    "word_list, data_predicted = word_finder(data,'Text')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data['Feedback_Label'] = data_predicted"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new = {'Text': word_list }\r\n",
    "new_data = pd.DataFrame(new)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_data.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                Text\n",
       "0  i love tracy reese dresses but this one is not...\n",
       "1  i love this dress i usually get an xs but it r...\n",
       "2  this is a nice choice for holiday gatherings i...\n",
       "3  material and color is nice  the leg opening is...\n",
       "4  i love the look and feel of this tulle dress i..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i love tracy reese dresses but this one is not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i love this dress i usually get an xs but it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a nice choice for holiday gatherings i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>material and color is nice  the leg opening is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i love the look and feel of this tulle dress i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(new_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6450"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# new_data.to_csv('opinion_data.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# text_cleaning = lambda x: light_text_cleaning_english(x)\r\n",
    "# new_data['Cleaned_Text'] = pd.DataFrame(new_data['Text'].apply(text_cleaning))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# common_list = most_used_words(new_data,'Text')\r\n",
    "# common_list"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "fa3fb38b5f65cee2ff0a035c4da5328998564043868f6520890cc31ef10c108b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}