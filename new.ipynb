{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import spacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#Extract twitter data\r\n",
    "data1 = pd.read_csv('datasets/Reddit_Data.csv', nrows=15000)\r\n",
    "data1.rename(columns = {'clean_comment': 'text'}, inplace = True)\r\n",
    "print(data1.head())\r\n",
    "print(len(data1))\r\n",
    "data2 = pd.read_csv('datasets/Twitter_Data.csv', nrows=15000)\r\n",
    "data2.rename(columns = {'clean_text': 'text'}, inplace = True)\r\n",
    "print(data2.head())\r\n",
    "print(len(data2))\r\n",
    "#Combine both dataframes into one master dataframe\r\n",
    "data = pd.concat([data1, data2], ignore_index = True)\r\n",
    "print(data.head())\r\n",
    "print(len(data))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                                                text  category\n",
      "0   family mormon have never tried explain them t...         1\n",
      "1  buddhism has very much lot compatible with chr...         1\n",
      "2  seriously don say thing first all they won get...        -1\n",
      "3  what you have learned yours and only yours wha...         0\n",
      "4  for your own benefit you may want read living ...         1\n",
      "15000\n",
      "                                                text  category\n",
      "0  when modi promised â€œminimum government maximum...        -1\n",
      "1  talk all the nonsense and continue all the dra...         0\n",
      "2  what did just say vote for modi  welcome bjp t...         1\n",
      "3  asking his supporters prefix chowkidar their n...         1\n",
      "4  answer who among these the most powerful world...         1\n",
      "15000\n",
      "                                                text  category\n",
      "0   family mormon have never tried explain them t...         1\n",
      "1  buddhism has very much lot compatible with chr...         1\n",
      "2  seriously don say thing first all they won get...        -1\n",
      "3  what you have learned yours and only yours wha...         0\n",
      "4  for your own benefit you may want read living ...         1\n",
      "30000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Preprocessing\r\n",
    "\r\n",
    "## Drop missing value\r\n",
    "data = data.dropna(axis = 0, how ='any')\r\n",
    "len(data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "29966"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "data['category'].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       " 1    12882\n",
       " 0    10137\n",
       "-1     6947\n",
       "Name: category, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\r\n",
    "from collections import Counter\r\n",
    "import string\r\n",
    "\r\n",
    "# Lemmatization\r\n",
    "def lemmetization(doc):\r\n",
    "    words = []\r\n",
    "    for word in doc:\r\n",
    "        if word.lemma_ != \"-PRON-\":\r\n",
    "            temp = word.lemma_.lower().strip()\r\n",
    "        else:\r\n",
    "            temp = word.lower_\r\n",
    "\r\n",
    "        words.append(temp)\r\n",
    "\r\n",
    "    return words\r\n",
    "\r\n",
    "# Remove punctuation and stopwords\r\n",
    "def punc_removal(doc):\r\n",
    "    words = []\r\n",
    "    for word in doc:\r\n",
    "        if word not in list(STOP_WORDS) and word not in string.punctuation:\r\n",
    "            words.append(word)\r\n",
    "    \r\n",
    "    return words\r\n",
    "\r\n",
    "save_words = []\r\n",
    "def text_cleaning_english(text,mynlp):\r\n",
    "\r\n",
    "    doc = mynlp(text)\r\n",
    "    # lemmetization\r\n",
    "    words = lemmetization(doc)\r\n",
    "    # remove punctuation\r\n",
    "    words = punc_removal(words)\r\n",
    "\r\n",
    "    # save all words in the data file\r\n",
    "    for word in words:\r\n",
    "        save_words.append(word)\r\n",
    "\r\n",
    "    # traverse in the string     \r\n",
    "    complete_sentence = ' '.join([str(word) for word in words])\r\n",
    "\r\n",
    "    return complete_sentence\r\n",
    "\r\n",
    "def most_used_words():\r\n",
    "    list = []\r\n",
    "    common_words = Counter(save_words).most_common(5)\r\n",
    "    for key, value in common_words:\r\n",
    "        list.append({'category': key, 'value': value})\r\n",
    "\r\n",
    "    return list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\r\n",
    "text_cleaning = lambda x: text_cleaning_english(x,mynlp=nlp)\r\n",
    "data['cleaned_text'] = pd.DataFrame(data['text'].apply(text_cleaning))\r\n",
    "\r\n",
    "common_words = most_used_words()\r\n",
    "print(common_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'category': 'modi', 'value': 16964}, {'category': 'india', 'value': 4835}, {'category': 'people', 'value': 4146}, {'category': 'bjp', 'value': 3627}, {'category': 'like', 'value': 3573}]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text  category  \\\n",
       "0       family mormon have never tried explain them t...         1   \n",
       "1      buddhism has very much lot compatible with chr...         1   \n",
       "2      seriously don say thing first all they won get...        -1   \n",
       "3      what you have learned yours and only yours wha...         0   \n",
       "4      for your own benefit you may want read living ...         1   \n",
       "...                                                  ...       ...   \n",
       "29995  well supporter modi you people hate modi just ...        -1   \n",
       "29996  pankaj tripathi mocking secularism the trailer...        -1   \n",
       "29997  nirav arrested\\nchoksi running but will caught...         1   \n",
       "29998  pakistan has islamic country and built islam t...         0   \n",
       "29999  each tweet you with similar message brings few...         1   \n",
       "\n",
       "                                            cleaned_text  \n",
       "0      family mormon try explain stare puzzle time ti...  \n",
       "1      buddhism lot compatible christianity especiall...  \n",
       "2      seriously don thing win complex explain normal...  \n",
       "3      learn want teach different focus goal wrap pap...  \n",
       "4      benefit want read live buddha living christ th...  \n",
       "...                                                  ...  \n",
       "29995  supporter modi people hate modi bcz 2002 riot ...  \n",
       "29996  pankaj tripathi mock secularism trailer vivek ...  \n",
       "29997  nirav arrest choksi run catch mallya bail good...  \n",
       "29998  pakistan islamic country build islam s whybeca...  \n",
       "29999  tweet similar message bring supporter work mod...  \n",
       "\n",
       "[29966 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "      <td>family mormon try explain stare puzzle time ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "      <td>buddhism lot compatible christianity especiall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "      <td>seriously don thing win complex explain normal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>learn want teach different focus goal wrap pap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "      <td>benefit want read live buddha living christ th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29995</th>\n",
       "      <td>well supporter modi you people hate modi just ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>supporter modi people hate modi bcz 2002 riot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29996</th>\n",
       "      <td>pankaj tripathi mocking secularism the trailer...</td>\n",
       "      <td>-1</td>\n",
       "      <td>pankaj tripathi mock secularism trailer vivek ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29997</th>\n",
       "      <td>nirav arrested\\nchoksi running but will caught...</td>\n",
       "      <td>1</td>\n",
       "      <td>nirav arrest choksi run catch mallya bail good...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29998</th>\n",
       "      <td>pakistan has islamic country and built islam t...</td>\n",
       "      <td>0</td>\n",
       "      <td>pakistan islamic country build islam s whybeca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29999</th>\n",
       "      <td>each tweet you with similar message brings few...</td>\n",
       "      <td>1</td>\n",
       "      <td>tweet similar message bring supporter work mod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29966 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# SPLIT TRAINING & TESTING DATA\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_text'],data['category'],test_size=0.2,shuffle=True, random_state=42)\r\n",
    "print(X_train.shape, y_train.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(23972,) (23972,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.svm import SVC \r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from xgboost import XGBClassifier\r\n",
    "from sklearn.linear_model import SGDClassifier\r\n",
    "from sklearn.naive_bayes import MultinomialNB\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score, precision_score, f1_score, recall_score\r\n",
    "\r\n",
    "def optimizer(data_train_input,data_train_target,model_type,data_test_input,data_test_target):\r\n",
    "    # Classifier selection\r\n",
    "    if model_type == \"linear\":\r\n",
    "        kernel=['linear', 'rbf', 'poly', 'sigmoid']\r\n",
    "\r\n",
    "        for i in kernel:\r\n",
    "            classifier = SVC(kernel=i,C=1.0)\r\n",
    "            tfidf = TfidfVectorizer()\r\n",
    "            clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\r\n",
    "            model = clf.fit(data_train_input,data_train_target)\r\n",
    "            print(model.score(data_test_input,data_test_target))\r\n",
    "\r\n",
    "def sentiment_pipeline(data_train_input,data_train_target,model_type,data_test_input,data_test_target):\r\n",
    "    # Classifier selection\r\n",
    "    if model_type == \"linear\":\r\n",
    "        classifier = SVC(random_state=42)\r\n",
    "        optimizer(data_train_input,data_train_target,model_type,data_test_input,data_test_target)\r\n",
    "    elif model_type == \"logistic\":\r\n",
    "        classifier = LogisticRegression(max_iter=200)\r\n",
    "    elif model_type == \"sgd\":\r\n",
    "        classifier = SGDClassifier()\r\n",
    "    elif model_type == \"naive_bayes\":\r\n",
    "        classifier = MultinomialNB()\r\n",
    "    elif model_type == \"xgboost\":\r\n",
    "        classifier = XGBClassifier(use_label_encoder=False,eta=0.1,gamma=0.3, n_estimators=100, learning_rate=0.5, min_child_weight=5, \r\n",
    "        max_depth=5, colsample_bytree=0.7,objective=\"multi:softmax\", eval_metric=\"mlogloss\",verbosity=0)\r\n",
    "\r\n",
    "    tfidf = TfidfVectorizer()\r\n",
    "\r\n",
    "    # Pipeline setup\r\n",
    "    clf = Pipeline([('tfidf', tfidf), ('clf', classifier)])\r\n",
    "\r\n",
    "    model = clf.fit(data_train_input,data_train_target)\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "def sentiment_model_predict(model,data_test_input,data_test_target):\r\n",
    "    data_prediction=model.predict(data_test_input)\r\n",
    "    conf_matrix = confusion_matrix(data_test_target,data_prediction)\r\n",
    "    acc_score = accuracy_score(data_test_target, data_prediction)\r\n",
    "    pre_score = precision_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "    re_score = recall_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "    f_score = f1_score(data_test_target, data_prediction, average=\"macro\")\r\n",
    "\r\n",
    "    print(\"Accuracy : \"+str(round(acc_score*100,2)))\r\n",
    "    print(\"Precision : \"+str(round(pre_score*100,2)))\r\n",
    "    print(\"Recall : \"+str(round(re_score*100,2)))\r\n",
    "    print(\"F1-Score :\"+str(round(f_score*100,2)))\r\n",
    "    print(conf_matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# Support Vector Classification\r\n",
    "model = sentiment_pipeline(X_train, y_train, 'linear',X_test,y_test)\r\n",
    "sentiment_model_predict(model,X_test,y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy : 76.89\n",
      "Precision : 76.39\n",
      "Recall : 75.63\n",
      "F1-Score :75.85\n",
      "[[ 913  202  274]\n",
      " [ 100 1684  240]\n",
      " [ 215  354 2012]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# # Logistic Regression\r\n",
    "# model = sentiment_pipeline(X_train, y_train, 'logistic')\r\n",
    "# sentiment_model_predict(model,X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# # Stochastic Gradient Descent\r\n",
    "# model = sentiment_pipeline(X_train, y_train, 'sgd')\r\n",
    "# sentiment_model_predict(model,X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# # Multinomial Naive Bayes\r\n",
    "# model = sentiment_pipeline(X_train, y_train, 'naive_bayes')\r\n",
    "# sentiment_model_predict(model,X_test,y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# # Xgboost\r\n",
    "# # change category value -1 to value 2\r\n",
    "# y_train_new = y_train.copy()\r\n",
    "# y_test_new = y_test.copy()\r\n",
    "# y_train_new.loc[y_train_new == -1] = 2\r\n",
    "# y_test_new.loc[y_test_new == -1] = 2\r\n",
    "\r\n",
    "# model = sentiment_pipeline(X_train, y_train_new, 'xgboost')\r\n",
    "# sentiment_model_predict(model,X_test,y_test_new)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "fa3fb38b5f65cee2ff0a035c4da5328998564043868f6520890cc31ef10c108b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}